{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install on Windows 10\n",
    "\n",
    "1. Make sure python and pip are installed. Update pip.\n",
    "2. Install by pip using `pip install --upgrade tensorflow`\n",
    "\n",
    "See [full install details](https://www.tensorflow.org/install/pip?hl=en#windows)\n",
    "\n",
    "See [gpu setup](https://www.tensorflow.org/install/gpu?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Example using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn')\n",
    "\n",
    "# keras\n",
    "import keras \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.metrics import CategoricalAccuracy, Recall, Precision, AUC\n",
    "from keras.backend import clear_session\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay, accuracy_score, precision_score, recall_score, precision_recall_curve, multilabel_confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "Classes of the data ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# read file\n",
    "file_path = '../pandas/data/iris.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "\n",
    "# feature-target split\n",
    "RSEED = 40\n",
    "X = df[df.columns[:-1]]\n",
    "y = df['species']\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "print('Classes of the data', le.classes_)\n",
    "y_int = le.transform(y) # class to integer\n",
    "y_encoded = np_utils.to_categorical(y_int) # integer to one-hot encode\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.414762</td>\n",
       "      <td>0.445833</td>\n",
       "      <td>0.461158</td>\n",
       "      <td>0.448611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.237317</td>\n",
       "      <td>0.182830</td>\n",
       "      <td>0.301678</td>\n",
       "      <td>0.318092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.567797</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    120.000000   120.000000    120.000000   120.000000\n",
       "mean       0.414762     0.445833      0.461158     0.448611\n",
       "std        0.237317     0.182830      0.301678     0.318092\n",
       "min        0.000000     0.000000      0.000000     0.000000\n",
       "25%        0.200000     0.333333      0.084746     0.083333\n",
       "50%        0.400000     0.416667      0.567797     0.500000\n",
       "75%        0.571429     0.541667      0.694915     0.708333\n",
       "max        1.000000     1.000000      1.000000     1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train_scaled.shape[1]))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# set up optimizer if needed\n",
    "#optz = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.0, nesterov = False)\n",
    "#optz = tf.keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy']\n",
    "              )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8837 - accuracy: 0.7083 - val_loss: 0.9180 - val_accuracy: 0.5833\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8819 - accuracy: 0.7083 - val_loss: 0.9162 - val_accuracy: 0.5833\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8801 - accuracy: 0.7083 - val_loss: 0.9144 - val_accuracy: 0.5833\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8783 - accuracy: 0.7083 - val_loss: 0.9126 - val_accuracy: 0.5833\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8765 - accuracy: 0.7083 - val_loss: 0.9109 - val_accuracy: 0.5833\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8746 - accuracy: 0.7083 - val_loss: 0.9091 - val_accuracy: 0.5833\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8728 - accuracy: 0.7083 - val_loss: 0.9073 - val_accuracy: 0.5833\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8710 - accuracy: 0.7083 - val_loss: 0.9055 - val_accuracy: 0.5833\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8692 - accuracy: 0.7083 - val_loss: 0.9038 - val_accuracy: 0.5833\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8674 - accuracy: 0.7083 - val_loss: 0.9020 - val_accuracy: 0.5833\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8656 - accuracy: 0.7083 - val_loss: 0.9002 - val_accuracy: 0.5833\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8638 - accuracy: 0.7083 - val_loss: 0.8985 - val_accuracy: 0.5833\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8620 - accuracy: 0.7083 - val_loss: 0.8967 - val_accuracy: 0.5833\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8602 - accuracy: 0.7083 - val_loss: 0.8950 - val_accuracy: 0.5833\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8584 - accuracy: 0.7083 - val_loss: 0.8932 - val_accuracy: 0.5833\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8566 - accuracy: 0.7083 - val_loss: 0.8914 - val_accuracy: 0.5833\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8548 - accuracy: 0.7083 - val_loss: 0.8897 - val_accuracy: 0.5833\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8530 - accuracy: 0.7083 - val_loss: 0.8879 - val_accuracy: 0.5833\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8513 - accuracy: 0.7083 - val_loss: 0.8862 - val_accuracy: 0.5833\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8495 - accuracy: 0.7083 - val_loss: 0.8844 - val_accuracy: 0.5833\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8477 - accuracy: 0.7083 - val_loss: 0.8827 - val_accuracy: 0.5833\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8459 - accuracy: 0.7083 - val_loss: 0.8809 - val_accuracy: 0.5833\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8441 - accuracy: 0.7083 - val_loss: 0.8792 - val_accuracy: 0.5833\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8423 - accuracy: 0.7083 - val_loss: 0.8774 - val_accuracy: 0.5833\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8406 - accuracy: 0.7083 - val_loss: 0.8757 - val_accuracy: 0.5833\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8388 - accuracy: 0.7083 - val_loss: 0.8739 - val_accuracy: 0.5833\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8370 - accuracy: 0.7083 - val_loss: 0.8722 - val_accuracy: 0.5833\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8352 - accuracy: 0.7083 - val_loss: 0.8704 - val_accuracy: 0.5833\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8335 - accuracy: 0.7083 - val_loss: 0.8687 - val_accuracy: 0.5833\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8317 - accuracy: 0.7083 - val_loss: 0.8670 - val_accuracy: 0.5833\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8299 - accuracy: 0.7083 - val_loss: 0.8653 - val_accuracy: 0.5833\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8282 - accuracy: 0.7083 - val_loss: 0.8635 - val_accuracy: 0.5833\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8264 - accuracy: 0.7083 - val_loss: 0.8618 - val_accuracy: 0.5833\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8247 - accuracy: 0.7083 - val_loss: 0.8601 - val_accuracy: 0.5833\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8229 - accuracy: 0.7083 - val_loss: 0.8584 - val_accuracy: 0.5833\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8212 - accuracy: 0.7083 - val_loss: 0.8567 - val_accuracy: 0.5833\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8194 - accuracy: 0.7083 - val_loss: 0.8550 - val_accuracy: 0.5833\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8177 - accuracy: 0.7083 - val_loss: 0.8534 - val_accuracy: 0.5833\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8160 - accuracy: 0.7083 - val_loss: 0.8517 - val_accuracy: 0.5833\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8142 - accuracy: 0.7083 - val_loss: 0.8500 - val_accuracy: 0.5833\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8125 - accuracy: 0.7083 - val_loss: 0.8483 - val_accuracy: 0.5833\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8108 - accuracy: 0.7083 - val_loss: 0.8467 - val_accuracy: 0.5833\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8091 - accuracy: 0.7083 - val_loss: 0.8450 - val_accuracy: 0.5833\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8073 - accuracy: 0.7083 - val_loss: 0.8433 - val_accuracy: 0.5833\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8056 - accuracy: 0.7083 - val_loss: 0.8417 - val_accuracy: 0.5833\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8039 - accuracy: 0.7083 - val_loss: 0.8400 - val_accuracy: 0.5833\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8022 - accuracy: 0.7083 - val_loss: 0.8384 - val_accuracy: 0.5833\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8005 - accuracy: 0.7083 - val_loss: 0.8367 - val_accuracy: 0.5833\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7988 - accuracy: 0.7083 - val_loss: 0.8351 - val_accuracy: 0.5833\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7971 - accuracy: 0.7083 - val_loss: 0.8334 - val_accuracy: 0.5833\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7955 - accuracy: 0.7083 - val_loss: 0.8318 - val_accuracy: 0.5833\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7938 - accuracy: 0.7083 - val_loss: 0.8302 - val_accuracy: 0.5833\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7921 - accuracy: 0.7083 - val_loss: 0.8285 - val_accuracy: 0.5833\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7904 - accuracy: 0.7083 - val_loss: 0.8269 - val_accuracy: 0.5833\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7888 - accuracy: 0.7083 - val_loss: 0.8253 - val_accuracy: 0.5833\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7871 - accuracy: 0.7083 - val_loss: 0.8237 - val_accuracy: 0.5833\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7855 - accuracy: 0.7083 - val_loss: 0.8220 - val_accuracy: 0.5833\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7838 - accuracy: 0.7083 - val_loss: 0.8204 - val_accuracy: 0.5833\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7822 - accuracy: 0.7083 - val_loss: 0.8188 - val_accuracy: 0.5833\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7805 - accuracy: 0.7083 - val_loss: 0.8172 - val_accuracy: 0.5833\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7789 - accuracy: 0.7083 - val_loss: 0.8156 - val_accuracy: 0.5833\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7773 - accuracy: 0.7083 - val_loss: 0.8141 - val_accuracy: 0.5833\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7756 - accuracy: 0.7083 - val_loss: 0.8125 - val_accuracy: 0.5833\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7740 - accuracy: 0.7083 - val_loss: 0.8109 - val_accuracy: 0.5833\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7724 - accuracy: 0.7083 - val_loss: 0.8093 - val_accuracy: 0.5833\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7708 - accuracy: 0.7083 - val_loss: 0.8078 - val_accuracy: 0.5833\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7692 - accuracy: 0.7083 - val_loss: 0.8062 - val_accuracy: 0.5833\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7676 - accuracy: 0.7083 - val_loss: 0.8046 - val_accuracy: 0.5833\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7660 - accuracy: 0.7083 - val_loss: 0.8031 - val_accuracy: 0.5833\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7644 - accuracy: 0.7083 - val_loss: 0.8015 - val_accuracy: 0.5833\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7628 - accuracy: 0.7083 - val_loss: 0.8000 - val_accuracy: 0.5833\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7613 - accuracy: 0.7083 - val_loss: 0.7984 - val_accuracy: 0.5833\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7597 - accuracy: 0.7083 - val_loss: 0.7969 - val_accuracy: 0.5833\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7581 - accuracy: 0.7083 - val_loss: 0.7954 - val_accuracy: 0.5833\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7565 - accuracy: 0.7083 - val_loss: 0.7938 - val_accuracy: 0.5833\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7550 - accuracy: 0.7083 - val_loss: 0.7923 - val_accuracy: 0.5833\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7534 - accuracy: 0.7083 - val_loss: 0.7908 - val_accuracy: 0.5833\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7519 - accuracy: 0.7083 - val_loss: 0.7893 - val_accuracy: 0.5833\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7504 - accuracy: 0.7083 - val_loss: 0.7878 - val_accuracy: 0.5833\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7488 - accuracy: 0.7083 - val_loss: 0.7863 - val_accuracy: 0.5833\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7473 - accuracy: 0.7083 - val_loss: 0.7849 - val_accuracy: 0.5833\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7458 - accuracy: 0.7083 - val_loss: 0.7834 - val_accuracy: 0.5833\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7443 - accuracy: 0.7083 - val_loss: 0.7820 - val_accuracy: 0.5833\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7427 - accuracy: 0.7083 - val_loss: 0.7805 - val_accuracy: 0.5833\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7412 - accuracy: 0.7083 - val_loss: 0.7791 - val_accuracy: 0.5833\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7397 - accuracy: 0.7083 - val_loss: 0.7776 - val_accuracy: 0.5833\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7382 - accuracy: 0.7083 - val_loss: 0.7761 - val_accuracy: 0.5833\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7367 - accuracy: 0.7083 - val_loss: 0.7747 - val_accuracy: 0.5833\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7353 - accuracy: 0.7083 - val_loss: 0.7733 - val_accuracy: 0.5833\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7338 - accuracy: 0.7083 - val_loss: 0.7718 - val_accuracy: 0.5833\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7323 - accuracy: 0.7083 - val_loss: 0.7704 - val_accuracy: 0.5833\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7308 - accuracy: 0.7083 - val_loss: 0.7690 - val_accuracy: 0.5833\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7294 - accuracy: 0.7083 - val_loss: 0.7675 - val_accuracy: 0.5833\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7279 - accuracy: 0.7083 - val_loss: 0.7661 - val_accuracy: 0.5833\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7265 - accuracy: 0.7083 - val_loss: 0.7647 - val_accuracy: 0.5833\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7250 - accuracy: 0.7083 - val_loss: 0.7633 - val_accuracy: 0.5833\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7236 - accuracy: 0.7083 - val_loss: 0.7619 - val_accuracy: 0.5833\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7222 - accuracy: 0.7083 - val_loss: 0.7605 - val_accuracy: 0.5833\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7207 - accuracy: 0.7083 - val_loss: 0.7591 - val_accuracy: 0.5833\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7193 - accuracy: 0.7083 - val_loss: 0.7577 - val_accuracy: 0.5833\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7179 - accuracy: 0.7083 - val_loss: 0.7563 - val_accuracy: 0.5833\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7165 - accuracy: 0.7083 - val_loss: 0.7550 - val_accuracy: 0.5833\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7151 - accuracy: 0.7083 - val_loss: 0.7536 - val_accuracy: 0.5833\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7137 - accuracy: 0.7083 - val_loss: 0.7522 - val_accuracy: 0.5833\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7123 - accuracy: 0.7083 - val_loss: 0.7509 - val_accuracy: 0.5833\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7109 - accuracy: 0.7083 - val_loss: 0.7495 - val_accuracy: 0.5833\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7095 - accuracy: 0.7083 - val_loss: 0.7482 - val_accuracy: 0.5833\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7082 - accuracy: 0.7083 - val_loss: 0.7468 - val_accuracy: 0.5833\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7068 - accuracy: 0.7083 - val_loss: 0.7455 - val_accuracy: 0.5833\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7054 - accuracy: 0.7083 - val_loss: 0.7441 - val_accuracy: 0.5833\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7041 - accuracy: 0.7083 - val_loss: 0.7428 - val_accuracy: 0.5833\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7027 - accuracy: 0.7083 - val_loss: 0.7415 - val_accuracy: 0.5833\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7014 - accuracy: 0.7083 - val_loss: 0.7402 - val_accuracy: 0.5833\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7000 - accuracy: 0.7083 - val_loss: 0.7389 - val_accuracy: 0.5833\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6987 - accuracy: 0.7083 - val_loss: 0.7376 - val_accuracy: 0.5833\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6974 - accuracy: 0.7083 - val_loss: 0.7363 - val_accuracy: 0.5833\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6961 - accuracy: 0.7083 - val_loss: 0.7350 - val_accuracy: 0.5833\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6948 - accuracy: 0.7083 - val_loss: 0.7337 - val_accuracy: 0.5833\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6934 - accuracy: 0.7083 - val_loss: 0.7324 - val_accuracy: 0.5833\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6921 - accuracy: 0.7083 - val_loss: 0.7311 - val_accuracy: 0.5833\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6908 - accuracy: 0.7083 - val_loss: 0.7298 - val_accuracy: 0.5833\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6895 - accuracy: 0.7083 - val_loss: 0.7286 - val_accuracy: 0.5833\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6883 - accuracy: 0.7083 - val_loss: 0.7273 - val_accuracy: 0.5833\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6870 - accuracy: 0.7083 - val_loss: 0.7260 - val_accuracy: 0.5833\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6857 - accuracy: 0.7083 - val_loss: 0.7248 - val_accuracy: 0.5833\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6844 - accuracy: 0.7083 - val_loss: 0.7235 - val_accuracy: 0.5833\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6832 - accuracy: 0.7083 - val_loss: 0.7223 - val_accuracy: 0.5833\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6819 - accuracy: 0.7083 - val_loss: 0.7211 - val_accuracy: 0.5833\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6807 - accuracy: 0.7083 - val_loss: 0.7198 - val_accuracy: 0.5833\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6794 - accuracy: 0.7083 - val_loss: 0.7186 - val_accuracy: 0.5833\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6782 - accuracy: 0.7083 - val_loss: 0.7174 - val_accuracy: 0.5833\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6769 - accuracy: 0.7083 - val_loss: 0.7161 - val_accuracy: 0.5833\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6757 - accuracy: 0.7083 - val_loss: 0.7149 - val_accuracy: 0.5833\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6745 - accuracy: 0.7083 - val_loss: 0.7137 - val_accuracy: 0.5833\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6732 - accuracy: 0.7083 - val_loss: 0.7124 - val_accuracy: 0.5833\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6720 - accuracy: 0.7083 - val_loss: 0.7112 - val_accuracy: 0.5833\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6708 - accuracy: 0.7083 - val_loss: 0.7100 - val_accuracy: 0.5833\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6696 - accuracy: 0.7083 - val_loss: 0.7088 - val_accuracy: 0.5833\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6684 - accuracy: 0.7083 - val_loss: 0.7076 - val_accuracy: 0.5833\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6672 - accuracy: 0.7083 - val_loss: 0.7064 - val_accuracy: 0.5833\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6660 - accuracy: 0.7083 - val_loss: 0.7052 - val_accuracy: 0.5833\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6649 - accuracy: 0.7083 - val_loss: 0.7040 - val_accuracy: 0.5833\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6637 - accuracy: 0.7083 - val_loss: 0.7028 - val_accuracy: 0.5833\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6625 - accuracy: 0.7083 - val_loss: 0.7017 - val_accuracy: 0.5833\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6613 - accuracy: 0.7083 - val_loss: 0.7005 - val_accuracy: 0.5833\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6602 - accuracy: 0.7083 - val_loss: 0.6993 - val_accuracy: 0.5833\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6590 - accuracy: 0.7083 - val_loss: 0.6982 - val_accuracy: 0.5833\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6579 - accuracy: 0.7083 - val_loss: 0.6970 - val_accuracy: 0.5833\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6567 - accuracy: 0.7083 - val_loss: 0.6959 - val_accuracy: 0.5833\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6556 - accuracy: 0.7083 - val_loss: 0.6948 - val_accuracy: 0.5833\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6545 - accuracy: 0.7083 - val_loss: 0.6936 - val_accuracy: 0.5833\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6533 - accuracy: 0.7083 - val_loss: 0.6925 - val_accuracy: 0.5833\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6522 - accuracy: 0.7083 - val_loss: 0.6914 - val_accuracy: 0.5833\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6511 - accuracy: 0.7083 - val_loss: 0.6902 - val_accuracy: 0.5833\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6500 - accuracy: 0.7083 - val_loss: 0.6891 - val_accuracy: 0.5833\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6489 - accuracy: 0.7083 - val_loss: 0.6880 - val_accuracy: 0.5833\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6478 - accuracy: 0.7083 - val_loss: 0.6869 - val_accuracy: 0.5833\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6467 - accuracy: 0.7083 - val_loss: 0.6858 - val_accuracy: 0.5833\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6456 - accuracy: 0.7083 - val_loss: 0.6847 - val_accuracy: 0.5833\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6445 - accuracy: 0.7083 - val_loss: 0.6836 - val_accuracy: 0.5833\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6434 - accuracy: 0.7083 - val_loss: 0.6825 - val_accuracy: 0.5833\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6423 - accuracy: 0.7083 - val_loss: 0.6814 - val_accuracy: 0.5833\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6413 - accuracy: 0.7083 - val_loss: 0.6803 - val_accuracy: 0.5833\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6402 - accuracy: 0.7083 - val_loss: 0.6792 - val_accuracy: 0.5833\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6391 - accuracy: 0.7083 - val_loss: 0.6782 - val_accuracy: 0.5833\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6381 - accuracy: 0.7083 - val_loss: 0.6771 - val_accuracy: 0.5833\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6370 - accuracy: 0.7083 - val_loss: 0.6760 - val_accuracy: 0.5833\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6360 - accuracy: 0.7083 - val_loss: 0.6749 - val_accuracy: 0.5833\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6349 - accuracy: 0.7083 - val_loss: 0.6739 - val_accuracy: 0.5833\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6339 - accuracy: 0.7083 - val_loss: 0.6728 - val_accuracy: 0.5833\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6329 - accuracy: 0.7083 - val_loss: 0.6718 - val_accuracy: 0.5833\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6318 - accuracy: 0.7083 - val_loss: 0.6708 - val_accuracy: 0.5833\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6308 - accuracy: 0.7083 - val_loss: 0.6697 - val_accuracy: 0.5833\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6298 - accuracy: 0.7083 - val_loss: 0.6687 - val_accuracy: 0.5833\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6288 - accuracy: 0.7083 - val_loss: 0.6676 - val_accuracy: 0.5833\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6278 - accuracy: 0.7083 - val_loss: 0.6666 - val_accuracy: 0.5833\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6268 - accuracy: 0.7083 - val_loss: 0.6656 - val_accuracy: 0.5833\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6258 - accuracy: 0.7083 - val_loss: 0.6646 - val_accuracy: 0.5833\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6248 - accuracy: 0.7083 - val_loss: 0.6636 - val_accuracy: 0.5833\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6238 - accuracy: 0.7083 - val_loss: 0.6626 - val_accuracy: 0.5833\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6228 - accuracy: 0.7083 - val_loss: 0.6616 - val_accuracy: 0.5833\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6218 - accuracy: 0.7083 - val_loss: 0.6606 - val_accuracy: 0.5833\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6208 - accuracy: 0.7083 - val_loss: 0.6596 - val_accuracy: 0.5833\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6199 - accuracy: 0.7083 - val_loss: 0.6586 - val_accuracy: 0.5833\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6189 - accuracy: 0.7083 - val_loss: 0.6576 - val_accuracy: 0.5833\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6179 - accuracy: 0.7083 - val_loss: 0.6567 - val_accuracy: 0.5833\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6170 - accuracy: 0.7083 - val_loss: 0.6557 - val_accuracy: 0.5833\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6160 - accuracy: 0.7083 - val_loss: 0.6547 - val_accuracy: 0.5833\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6151 - accuracy: 0.7083 - val_loss: 0.6538 - val_accuracy: 0.5833\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6141 - accuracy: 0.7083 - val_loss: 0.6528 - val_accuracy: 0.5833\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6132 - accuracy: 0.7083 - val_loss: 0.6519 - val_accuracy: 0.5833\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6122 - accuracy: 0.7083 - val_loss: 0.6509 - val_accuracy: 0.5833\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6113 - accuracy: 0.7083 - val_loss: 0.6500 - val_accuracy: 0.5833\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6104 - accuracy: 0.7083 - val_loss: 0.6490 - val_accuracy: 0.5833\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6094 - accuracy: 0.7083 - val_loss: 0.6481 - val_accuracy: 0.5833\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6085 - accuracy: 0.7083 - val_loss: 0.6471 - val_accuracy: 0.5833\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6076 - accuracy: 0.7083 - val_loss: 0.6462 - val_accuracy: 0.5833\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6067 - accuracy: 0.7083 - val_loss: 0.6453 - val_accuracy: 0.5833\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6058 - accuracy: 0.7083 - val_loss: 0.6444 - val_accuracy: 0.5833\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6049 - accuracy: 0.7083 - val_loss: 0.6434 - val_accuracy: 0.5833\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6040 - accuracy: 0.7083 - val_loss: 0.6425 - val_accuracy: 0.5833\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6031 - accuracy: 0.7083 - val_loss: 0.6416 - val_accuracy: 0.5833\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6022 - accuracy: 0.7083 - val_loss: 0.6407 - val_accuracy: 0.5833\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6013 - accuracy: 0.7083 - val_loss: 0.6397 - val_accuracy: 0.5833\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6004 - accuracy: 0.7083 - val_loss: 0.6388 - val_accuracy: 0.5833\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5995 - accuracy: 0.7083 - val_loss: 0.6379 - val_accuracy: 0.5833\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5987 - accuracy: 0.7083 - val_loss: 0.6370 - val_accuracy: 0.5833\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5978 - accuracy: 0.7083 - val_loss: 0.6361 - val_accuracy: 0.5833\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5969 - accuracy: 0.7083 - val_loss: 0.6352 - val_accuracy: 0.5833\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5961 - accuracy: 0.7083 - val_loss: 0.6343 - val_accuracy: 0.5833\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5952 - accuracy: 0.7083 - val_loss: 0.6334 - val_accuracy: 0.5833\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5943 - accuracy: 0.7083 - val_loss: 0.6325 - val_accuracy: 0.5833\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5935 - accuracy: 0.7083 - val_loss: 0.6317 - val_accuracy: 0.5833\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5926 - accuracy: 0.7083 - val_loss: 0.6308 - val_accuracy: 0.5833\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5918 - accuracy: 0.7083 - val_loss: 0.6299 - val_accuracy: 0.5833\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5910 - accuracy: 0.7083 - val_loss: 0.6290 - val_accuracy: 0.5833\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5901 - accuracy: 0.7083 - val_loss: 0.6281 - val_accuracy: 0.5833\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5893 - accuracy: 0.7083 - val_loss: 0.6273 - val_accuracy: 0.5833\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5885 - accuracy: 0.7083 - val_loss: 0.6264 - val_accuracy: 0.5833\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5876 - accuracy: 0.7083 - val_loss: 0.6256 - val_accuracy: 0.5833\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5868 - accuracy: 0.7083 - val_loss: 0.6247 - val_accuracy: 0.5833\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5860 - accuracy: 0.7083 - val_loss: 0.6239 - val_accuracy: 0.5833\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5852 - accuracy: 0.7083 - val_loss: 0.6230 - val_accuracy: 0.5833\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5844 - accuracy: 0.7083 - val_loss: 0.6222 - val_accuracy: 0.5833\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5836 - accuracy: 0.7083 - val_loss: 0.6214 - val_accuracy: 0.5833\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5827 - accuracy: 0.7083 - val_loss: 0.6206 - val_accuracy: 0.5833\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5819 - accuracy: 0.7083 - val_loss: 0.6197 - val_accuracy: 0.5833\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5811 - accuracy: 0.7083 - val_loss: 0.6189 - val_accuracy: 0.5833\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5804 - accuracy: 0.7083 - val_loss: 0.6181 - val_accuracy: 0.5833\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5796 - accuracy: 0.7083 - val_loss: 0.6173 - val_accuracy: 0.5833\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5788 - accuracy: 0.7083 - val_loss: 0.6165 - val_accuracy: 0.5833\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5780 - accuracy: 0.7083 - val_loss: 0.6157 - val_accuracy: 0.5833\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5772 - accuracy: 0.7083 - val_loss: 0.6150 - val_accuracy: 0.5833\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5764 - accuracy: 0.7083 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5757 - accuracy: 0.7083 - val_loss: 0.6134 - val_accuracy: 0.5833\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5749 - accuracy: 0.7083 - val_loss: 0.6126 - val_accuracy: 0.5833\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5741 - accuracy: 0.7083 - val_loss: 0.6118 - val_accuracy: 0.5833\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5733 - accuracy: 0.7083 - val_loss: 0.6110 - val_accuracy: 0.5833\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5726 - accuracy: 0.7083 - val_loss: 0.6102 - val_accuracy: 0.5833\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5718 - accuracy: 0.7083 - val_loss: 0.6094 - val_accuracy: 0.5833\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5711 - accuracy: 0.7083 - val_loss: 0.6087 - val_accuracy: 0.5833\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5703 - accuracy: 0.7083 - val_loss: 0.6079 - val_accuracy: 0.5833\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5696 - accuracy: 0.7083 - val_loss: 0.6071 - val_accuracy: 0.5833\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5688 - accuracy: 0.7083 - val_loss: 0.6063 - val_accuracy: 0.5833\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5681 - accuracy: 0.7083 - val_loss: 0.6056 - val_accuracy: 0.5833\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5673 - accuracy: 0.7083 - val_loss: 0.6048 - val_accuracy: 0.5833\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5666 - accuracy: 0.7083 - val_loss: 0.6040 - val_accuracy: 0.5833\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5659 - accuracy: 0.7083 - val_loss: 0.6033 - val_accuracy: 0.5833\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5651 - accuracy: 0.7083 - val_loss: 0.6025 - val_accuracy: 0.5833\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5644 - accuracy: 0.7083 - val_loss: 0.6017 - val_accuracy: 0.5833\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5637 - accuracy: 0.7083 - val_loss: 0.6010 - val_accuracy: 0.5833\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5630 - accuracy: 0.7083 - val_loss: 0.6002 - val_accuracy: 0.5833\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5622 - accuracy: 0.7083 - val_loss: 0.5995 - val_accuracy: 0.5833\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5615 - accuracy: 0.7083 - val_loss: 0.5987 - val_accuracy: 0.5833\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5608 - accuracy: 0.7083 - val_loss: 0.5980 - val_accuracy: 0.5833\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5601 - accuracy: 0.7083 - val_loss: 0.5972 - val_accuracy: 0.5833\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5594 - accuracy: 0.7083 - val_loss: 0.5965 - val_accuracy: 0.5833\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5587 - accuracy: 0.7083 - val_loss: 0.5957 - val_accuracy: 0.5833\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5580 - accuracy: 0.7083 - val_loss: 0.5950 - val_accuracy: 0.5833\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5573 - accuracy: 0.7083 - val_loss: 0.5943 - val_accuracy: 0.5833\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5566 - accuracy: 0.7083 - val_loss: 0.5935 - val_accuracy: 0.5833\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5559 - accuracy: 0.7083 - val_loss: 0.5928 - val_accuracy: 0.5833\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5552 - accuracy: 0.7083 - val_loss: 0.5921 - val_accuracy: 0.5833\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5545 - accuracy: 0.7083 - val_loss: 0.5913 - val_accuracy: 0.5833\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5538 - accuracy: 0.7083 - val_loss: 0.5906 - val_accuracy: 0.5833\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5531 - accuracy: 0.7083 - val_loss: 0.5899 - val_accuracy: 0.5833\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5525 - accuracy: 0.7083 - val_loss: 0.5892 - val_accuracy: 0.5833\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5518 - accuracy: 0.7083 - val_loss: 0.5885 - val_accuracy: 0.5833\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5511 - accuracy: 0.7083 - val_loss: 0.5877 - val_accuracy: 0.5833\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5504 - accuracy: 0.7083 - val_loss: 0.5870 - val_accuracy: 0.5833\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5498 - accuracy: 0.7083 - val_loss: 0.5863 - val_accuracy: 0.5833\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5491 - accuracy: 0.7083 - val_loss: 0.5856 - val_accuracy: 0.5833\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5484 - accuracy: 0.7083 - val_loss: 0.5849 - val_accuracy: 0.5833\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5478 - accuracy: 0.7083 - val_loss: 0.5842 - val_accuracy: 0.5833\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5471 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.5833\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5465 - accuracy: 0.7083 - val_loss: 0.5828 - val_accuracy: 0.5833\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5458 - accuracy: 0.7083 - val_loss: 0.5821 - val_accuracy: 0.5833\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5452 - accuracy: 0.7083 - val_loss: 0.5814 - val_accuracy: 0.5833\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5445 - accuracy: 0.7083 - val_loss: 0.5807 - val_accuracy: 0.5833\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5439 - accuracy: 0.7083 - val_loss: 0.5800 - val_accuracy: 0.5833\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5432 - accuracy: 0.7083 - val_loss: 0.5793 - val_accuracy: 0.5833\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5426 - accuracy: 0.7083 - val_loss: 0.5786 - val_accuracy: 0.5833\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5419 - accuracy: 0.7083 - val_loss: 0.5780 - val_accuracy: 0.5833\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5413 - accuracy: 0.7083 - val_loss: 0.5773 - val_accuracy: 0.5833\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5407 - accuracy: 0.7083 - val_loss: 0.5766 - val_accuracy: 0.5833\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5400 - accuracy: 0.7083 - val_loss: 0.5760 - val_accuracy: 0.5833\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5394 - accuracy: 0.7083 - val_loss: 0.5753 - val_accuracy: 0.5833\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5388 - accuracy: 0.7083 - val_loss: 0.5746 - val_accuracy: 0.5833\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5381 - accuracy: 0.7083 - val_loss: 0.5739 - val_accuracy: 0.5833\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5375 - accuracy: 0.7083 - val_loss: 0.5733 - val_accuracy: 0.5833\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5369 - accuracy: 0.7083 - val_loss: 0.5726 - val_accuracy: 0.5833\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5363 - accuracy: 0.7083 - val_loss: 0.5720 - val_accuracy: 0.5833\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5356 - accuracy: 0.7083 - val_loss: 0.5713 - val_accuracy: 0.5833\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5350 - accuracy: 0.7083 - val_loss: 0.5706 - val_accuracy: 0.5833\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5344 - accuracy: 0.7083 - val_loss: 0.5700 - val_accuracy: 0.5833\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5338 - accuracy: 0.7083 - val_loss: 0.5693 - val_accuracy: 0.5833\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5332 - accuracy: 0.7083 - val_loss: 0.5687 - val_accuracy: 0.5833\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5326 - accuracy: 0.7083 - val_loss: 0.5680 - val_accuracy: 0.5833\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5320 - accuracy: 0.7083 - val_loss: 0.5674 - val_accuracy: 0.5833\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5314 - accuracy: 0.7083 - val_loss: 0.5667 - val_accuracy: 0.5833\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5308 - accuracy: 0.7083 - val_loss: 0.5661 - val_accuracy: 0.5833\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5302 - accuracy: 0.7083 - val_loss: 0.5655 - val_accuracy: 0.5833\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5296 - accuracy: 0.7083 - val_loss: 0.5648 - val_accuracy: 0.5833\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5290 - accuracy: 0.7083 - val_loss: 0.5642 - val_accuracy: 0.5833\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5284 - accuracy: 0.7083 - val_loss: 0.5636 - val_accuracy: 0.5833\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5278 - accuracy: 0.7083 - val_loss: 0.5629 - val_accuracy: 0.5833\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5272 - accuracy: 0.7083 - val_loss: 0.5623 - val_accuracy: 0.5833\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5266 - accuracy: 0.7083 - val_loss: 0.5617 - val_accuracy: 0.5833\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5261 - accuracy: 0.7083 - val_loss: 0.5610 - val_accuracy: 0.5833\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5255 - accuracy: 0.7083 - val_loss: 0.5604 - val_accuracy: 0.5833\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5249 - accuracy: 0.7083 - val_loss: 0.5598 - val_accuracy: 0.5833\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5243 - accuracy: 0.7083 - val_loss: 0.5592 - val_accuracy: 0.5833\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5238 - accuracy: 0.7083 - val_loss: 0.5585 - val_accuracy: 0.5833\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5232 - accuracy: 0.7083 - val_loss: 0.5579 - val_accuracy: 0.5833\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5226 - accuracy: 0.7083 - val_loss: 0.5573 - val_accuracy: 0.5833\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5220 - accuracy: 0.7083 - val_loss: 0.5567 - val_accuracy: 0.5833\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5215 - accuracy: 0.7083 - val_loss: 0.5560 - val_accuracy: 0.5833\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5209 - accuracy: 0.7083 - val_loss: 0.5554 - val_accuracy: 0.5833\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5203 - accuracy: 0.7083 - val_loss: 0.5548 - val_accuracy: 0.5833\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5198 - accuracy: 0.7083 - val_loss: 0.5542 - val_accuracy: 0.5833\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5192 - accuracy: 0.7083 - val_loss: 0.5536 - val_accuracy: 0.5833\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5187 - accuracy: 0.7083 - val_loss: 0.5530 - val_accuracy: 0.5833\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5181 - accuracy: 0.7083 - val_loss: 0.5523 - val_accuracy: 0.5833\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5175 - accuracy: 0.7083 - val_loss: 0.5517 - val_accuracy: 0.5833\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5170 - accuracy: 0.7083 - val_loss: 0.5511 - val_accuracy: 0.5833\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5164 - accuracy: 0.7083 - val_loss: 0.5505 - val_accuracy: 0.5833\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5159 - accuracy: 0.7083 - val_loss: 0.5499 - val_accuracy: 0.5833\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5153 - accuracy: 0.7083 - val_loss: 0.5493 - val_accuracy: 0.5833\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5148 - accuracy: 0.7083 - val_loss: 0.5487 - val_accuracy: 0.5833\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5142 - accuracy: 0.7083 - val_loss: 0.5481 - val_accuracy: 0.5833\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5137 - accuracy: 0.7083 - val_loss: 0.5475 - val_accuracy: 0.5833\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5132 - accuracy: 0.7188 - val_loss: 0.5469 - val_accuracy: 0.5833\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5126 - accuracy: 0.7188 - val_loss: 0.5463 - val_accuracy: 0.5833\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5121 - accuracy: 0.7292 - val_loss: 0.5457 - val_accuracy: 0.5833\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5115 - accuracy: 0.7292 - val_loss: 0.5451 - val_accuracy: 0.5833\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5110 - accuracy: 0.7292 - val_loss: 0.5445 - val_accuracy: 0.5833\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5105 - accuracy: 0.7292 - val_loss: 0.5439 - val_accuracy: 0.5833\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5099 - accuracy: 0.7292 - val_loss: 0.5433 - val_accuracy: 0.5833\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5094 - accuracy: 0.7292 - val_loss: 0.5428 - val_accuracy: 0.5833\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5089 - accuracy: 0.7292 - val_loss: 0.5422 - val_accuracy: 0.5833\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5083 - accuracy: 0.7292 - val_loss: 0.5416 - val_accuracy: 0.5833\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5078 - accuracy: 0.7292 - val_loss: 0.5410 - val_accuracy: 0.5833\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5073 - accuracy: 0.7292 - val_loss: 0.5404 - val_accuracy: 0.5833\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5068 - accuracy: 0.7292 - val_loss: 0.5399 - val_accuracy: 0.5833\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5062 - accuracy: 0.7292 - val_loss: 0.5393 - val_accuracy: 0.5833\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5057 - accuracy: 0.7292 - val_loss: 0.5387 - val_accuracy: 0.5833\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5052 - accuracy: 0.7292 - val_loss: 0.5382 - val_accuracy: 0.5833\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5047 - accuracy: 0.7292 - val_loss: 0.5376 - val_accuracy: 0.5833\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5042 - accuracy: 0.7292 - val_loss: 0.5370 - val_accuracy: 0.5833\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5036 - accuracy: 0.7292 - val_loss: 0.5365 - val_accuracy: 0.5833\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5031 - accuracy: 0.7292 - val_loss: 0.5359 - val_accuracy: 0.5833\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5026 - accuracy: 0.7292 - val_loss: 0.5354 - val_accuracy: 0.5833\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5021 - accuracy: 0.7292 - val_loss: 0.5348 - val_accuracy: 0.5833\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5016 - accuracy: 0.7292 - val_loss: 0.5343 - val_accuracy: 0.5833\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5011 - accuracy: 0.7292 - val_loss: 0.5337 - val_accuracy: 0.5833\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5006 - accuracy: 0.7292 - val_loss: 0.5332 - val_accuracy: 0.5833\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5001 - accuracy: 0.7396 - val_loss: 0.5327 - val_accuracy: 0.5833\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4996 - accuracy: 0.7396 - val_loss: 0.5321 - val_accuracy: 0.5833\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4991 - accuracy: 0.7396 - val_loss: 0.5316 - val_accuracy: 0.5833\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4986 - accuracy: 0.7396 - val_loss: 0.5311 - val_accuracy: 0.5833\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4981 - accuracy: 0.7396 - val_loss: 0.5306 - val_accuracy: 0.5833\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4976 - accuracy: 0.7396 - val_loss: 0.5300 - val_accuracy: 0.5833\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4971 - accuracy: 0.7396 - val_loss: 0.5295 - val_accuracy: 0.5833\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4966 - accuracy: 0.7396 - val_loss: 0.5289 - val_accuracy: 0.5833\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4961 - accuracy: 0.7396 - val_loss: 0.5284 - val_accuracy: 0.5833\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4956 - accuracy: 0.7396 - val_loss: 0.5279 - val_accuracy: 0.5833\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4951 - accuracy: 0.7396 - val_loss: 0.5273 - val_accuracy: 0.5833\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4946 - accuracy: 0.7396 - val_loss: 0.5268 - val_accuracy: 0.5833\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4941 - accuracy: 0.7396 - val_loss: 0.5263 - val_accuracy: 0.5833\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4936 - accuracy: 0.7396 - val_loss: 0.5257 - val_accuracy: 0.5833\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4931 - accuracy: 0.7396 - val_loss: 0.5252 - val_accuracy: 0.5833\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4926 - accuracy: 0.7396 - val_loss: 0.5247 - val_accuracy: 0.5833\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4921 - accuracy: 0.7396 - val_loss: 0.5241 - val_accuracy: 0.5833\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4916 - accuracy: 0.7396 - val_loss: 0.5236 - val_accuracy: 0.5833\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4912 - accuracy: 0.7396 - val_loss: 0.5231 - val_accuracy: 0.5833\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4907 - accuracy: 0.7396 - val_loss: 0.5226 - val_accuracy: 0.5833\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4902 - accuracy: 0.7396 - val_loss: 0.5220 - val_accuracy: 0.5833\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4897 - accuracy: 0.7396 - val_loss: 0.5215 - val_accuracy: 0.5833\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4892 - accuracy: 0.7396 - val_loss: 0.5210 - val_accuracy: 0.5833\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4888 - accuracy: 0.7396 - val_loss: 0.5204 - val_accuracy: 0.5833\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4883 - accuracy: 0.7396 - val_loss: 0.5199 - val_accuracy: 0.5833\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4878 - accuracy: 0.7396 - val_loss: 0.5194 - val_accuracy: 0.5833\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4873 - accuracy: 0.7396 - val_loss: 0.5188 - val_accuracy: 0.5833\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4869 - accuracy: 0.7396 - val_loss: 0.5183 - val_accuracy: 0.5833\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4864 - accuracy: 0.7396 - val_loss: 0.5178 - val_accuracy: 0.5833\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4859 - accuracy: 0.7396 - val_loss: 0.5173 - val_accuracy: 0.5833\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4854 - accuracy: 0.7396 - val_loss: 0.5167 - val_accuracy: 0.5833\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4850 - accuracy: 0.7396 - val_loss: 0.5162 - val_accuracy: 0.5833\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4845 - accuracy: 0.7396 - val_loss: 0.5157 - val_accuracy: 0.5833\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4840 - accuracy: 0.7396 - val_loss: 0.5152 - val_accuracy: 0.5833\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4836 - accuracy: 0.7396 - val_loss: 0.5146 - val_accuracy: 0.5833\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4831 - accuracy: 0.7396 - val_loss: 0.5141 - val_accuracy: 0.5833\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4826 - accuracy: 0.7396 - val_loss: 0.5136 - val_accuracy: 0.5833\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4822 - accuracy: 0.7396 - val_loss: 0.5130 - val_accuracy: 0.5833\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4817 - accuracy: 0.7396 - val_loss: 0.5125 - val_accuracy: 0.5833\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4813 - accuracy: 0.7396 - val_loss: 0.5120 - val_accuracy: 0.5833\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4808 - accuracy: 0.7396 - val_loss: 0.5115 - val_accuracy: 0.5833\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4803 - accuracy: 0.7396 - val_loss: 0.5109 - val_accuracy: 0.5833\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4799 - accuracy: 0.7396 - val_loss: 0.5104 - val_accuracy: 0.5833\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4794 - accuracy: 0.7396 - val_loss: 0.5099 - val_accuracy: 0.5833\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4790 - accuracy: 0.7396 - val_loss: 0.5094 - val_accuracy: 0.5833\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4785 - accuracy: 0.7396 - val_loss: 0.5089 - val_accuracy: 0.5833\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4781 - accuracy: 0.7396 - val_loss: 0.5084 - val_accuracy: 0.5833\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4776 - accuracy: 0.7396 - val_loss: 0.5079 - val_accuracy: 0.5833\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4772 - accuracy: 0.7396 - val_loss: 0.5074 - val_accuracy: 0.5833\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7396 - val_loss: 0.5069 - val_accuracy: 0.5833\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4763 - accuracy: 0.7396 - val_loss: 0.5063 - val_accuracy: 0.5833\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4758 - accuracy: 0.7396 - val_loss: 0.5058 - val_accuracy: 0.5833\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4754 - accuracy: 0.7396 - val_loss: 0.5053 - val_accuracy: 0.5833\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4749 - accuracy: 0.7396 - val_loss: 0.5048 - val_accuracy: 0.5833\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4745 - accuracy: 0.7396 - val_loss: 0.5043 - val_accuracy: 0.5833\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4740 - accuracy: 0.7396 - val_loss: 0.5038 - val_accuracy: 0.5833\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4736 - accuracy: 0.7396 - val_loss: 0.5033 - val_accuracy: 0.5833\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4731 - accuracy: 0.7396 - val_loss: 0.5029 - val_accuracy: 0.5833\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4727 - accuracy: 0.7396 - val_loss: 0.5024 - val_accuracy: 0.5833\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4722 - accuracy: 0.7396 - val_loss: 0.5019 - val_accuracy: 0.5833\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4718 - accuracy: 0.7396 - val_loss: 0.5014 - val_accuracy: 0.5833\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4714 - accuracy: 0.7396 - val_loss: 0.5009 - val_accuracy: 0.5833\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4709 - accuracy: 0.7396 - val_loss: 0.5004 - val_accuracy: 0.5833\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4705 - accuracy: 0.7396 - val_loss: 0.5000 - val_accuracy: 0.5833\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4701 - accuracy: 0.7396 - val_loss: 0.4995 - val_accuracy: 0.5833\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4696 - accuracy: 0.7396 - val_loss: 0.4990 - val_accuracy: 0.5833\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4692 - accuracy: 0.7396 - val_loss: 0.4986 - val_accuracy: 0.5833\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4688 - accuracy: 0.7396 - val_loss: 0.4981 - val_accuracy: 0.5833\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4683 - accuracy: 0.7396 - val_loss: 0.4976 - val_accuracy: 0.5833\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4679 - accuracy: 0.7396 - val_loss: 0.4971 - val_accuracy: 0.5833\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4675 - accuracy: 0.7500 - val_loss: 0.4967 - val_accuracy: 0.5833\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4670 - accuracy: 0.7500 - val_loss: 0.4962 - val_accuracy: 0.5833\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4666 - accuracy: 0.7500 - val_loss: 0.4957 - val_accuracy: 0.5833\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4662 - accuracy: 0.7500 - val_loss: 0.4952 - val_accuracy: 0.5833\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4657 - accuracy: 0.7500 - val_loss: 0.4948 - val_accuracy: 0.5833\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4653 - accuracy: 0.7500 - val_loss: 0.4943 - val_accuracy: 0.5833\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4649 - accuracy: 0.7500 - val_loss: 0.4938 - val_accuracy: 0.5833\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4645 - accuracy: 0.7604 - val_loss: 0.4934 - val_accuracy: 0.5833\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4640 - accuracy: 0.7604 - val_loss: 0.4929 - val_accuracy: 0.5833\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.5833\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.5833\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.5833\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4623 - accuracy: 0.7708 - val_loss: 0.4910 - val_accuracy: 0.5833\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.4905 - val_accuracy: 0.6250\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.6250\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.6250\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4607 - accuracy: 0.7708 - val_loss: 0.4890 - val_accuracy: 0.6250\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4885 - val_accuracy: 0.6250\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4598 - accuracy: 0.7708 - val_loss: 0.4880 - val_accuracy: 0.6250\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4876 - val_accuracy: 0.6250\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4871 - val_accuracy: 0.6250\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.4866 - val_accuracy: 0.6250\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4582 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.6250\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4577 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.6250\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.4851 - val_accuracy: 0.6250\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.4846 - val_accuracy: 0.6250\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.6250\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.4836 - val_accuracy: 0.6250\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.4831 - val_accuracy: 0.6250\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.4826 - val_accuracy: 0.6250\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4549 - accuracy: 0.7708 - val_loss: 0.4821 - val_accuracy: 0.6250\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.6250\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4540 - accuracy: 0.7708 - val_loss: 0.4812 - val_accuracy: 0.6250\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4536 - accuracy: 0.7708 - val_loss: 0.4807 - val_accuracy: 0.6250\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.4802 - val_accuracy: 0.6250\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4528 - accuracy: 0.7708 - val_loss: 0.4798 - val_accuracy: 0.6250\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4524 - accuracy: 0.7708 - val_loss: 0.4793 - val_accuracy: 0.6250\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.4788 - val_accuracy: 0.6250\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4516 - accuracy: 0.7708 - val_loss: 0.4784 - val_accuracy: 0.6250\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4512 - accuracy: 0.7708 - val_loss: 0.4779 - val_accuracy: 0.6250\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4508 - accuracy: 0.7812 - val_loss: 0.4775 - val_accuracy: 0.6250\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.4770 - val_accuracy: 0.6250\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.4766 - val_accuracy: 0.6250\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.4761 - val_accuracy: 0.6250\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4492 - accuracy: 0.7917 - val_loss: 0.4757 - val_accuracy: 0.6250\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4488 - accuracy: 0.7917 - val_loss: 0.4752 - val_accuracy: 0.6250\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4484 - accuracy: 0.8021 - val_loss: 0.4748 - val_accuracy: 0.6250\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4480 - accuracy: 0.8021 - val_loss: 0.4743 - val_accuracy: 0.6250\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4476 - accuracy: 0.8021 - val_loss: 0.4739 - val_accuracy: 0.6250\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4472 - accuracy: 0.8021 - val_loss: 0.4734 - val_accuracy: 0.6250\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4468 - accuracy: 0.8021 - val_loss: 0.4729 - val_accuracy: 0.6250\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4464 - accuracy: 0.8021 - val_loss: 0.4725 - val_accuracy: 0.6250\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4460 - accuracy: 0.8021 - val_loss: 0.4720 - val_accuracy: 0.6250\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4456 - accuracy: 0.8021 - val_loss: 0.4715 - val_accuracy: 0.6250\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4452 - accuracy: 0.8021 - val_loss: 0.4710 - val_accuracy: 0.6250\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4449 - accuracy: 0.8021 - val_loss: 0.4706 - val_accuracy: 0.6250\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4445 - accuracy: 0.8021 - val_loss: 0.4701 - val_accuracy: 0.6250\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4441 - accuracy: 0.8021 - val_loss: 0.4696 - val_accuracy: 0.6250\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4437 - accuracy: 0.8125 - val_loss: 0.4692 - val_accuracy: 0.6250\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4433 - accuracy: 0.8125 - val_loss: 0.4687 - val_accuracy: 0.6250\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4429 - accuracy: 0.8125 - val_loss: 0.4682 - val_accuracy: 0.6250\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4425 - accuracy: 0.8125 - val_loss: 0.4677 - val_accuracy: 0.6250\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4421 - accuracy: 0.8125 - val_loss: 0.4673 - val_accuracy: 0.6250\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4417 - accuracy: 0.8125 - val_loss: 0.4668 - val_accuracy: 0.6250\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4413 - accuracy: 0.8125 - val_loss: 0.4663 - val_accuracy: 0.6250\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4409 - accuracy: 0.8125 - val_loss: 0.4659 - val_accuracy: 0.6250\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4406 - accuracy: 0.8125 - val_loss: 0.4654 - val_accuracy: 0.6250\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4402 - accuracy: 0.8125 - val_loss: 0.4649 - val_accuracy: 0.6250\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4398 - accuracy: 0.8125 - val_loss: 0.4644 - val_accuracy: 0.6250\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4394 - accuracy: 0.8125 - val_loss: 0.4640 - val_accuracy: 0.6667\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4390 - accuracy: 0.8125 - val_loss: 0.4635 - val_accuracy: 0.6667\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4386 - accuracy: 0.8125 - val_loss: 0.4630 - val_accuracy: 0.6667\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4382 - accuracy: 0.8125 - val_loss: 0.4625 - val_accuracy: 0.6667\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4378 - accuracy: 0.8125 - val_loss: 0.4621 - val_accuracy: 0.6667\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4375 - accuracy: 0.8125 - val_loss: 0.4616 - val_accuracy: 0.6667\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4371 - accuracy: 0.8125 - val_loss: 0.4611 - val_accuracy: 0.6667\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4367 - accuracy: 0.8125 - val_loss: 0.4606 - val_accuracy: 0.6667\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4363 - accuracy: 0.8125 - val_loss: 0.4602 - val_accuracy: 0.6667\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4359 - accuracy: 0.8125 - val_loss: 0.4597 - val_accuracy: 0.6667\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4355 - accuracy: 0.8125 - val_loss: 0.4592 - val_accuracy: 0.6667\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4351 - accuracy: 0.8125 - val_loss: 0.4588 - val_accuracy: 0.6667\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4348 - accuracy: 0.8125 - val_loss: 0.4584 - val_accuracy: 0.6667\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4344 - accuracy: 0.8125 - val_loss: 0.4579 - val_accuracy: 0.6667\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4340 - accuracy: 0.8125 - val_loss: 0.4575 - val_accuracy: 0.6667\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4336 - accuracy: 0.8125 - val_loss: 0.4570 - val_accuracy: 0.7083\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4332 - accuracy: 0.8125 - val_loss: 0.4566 - val_accuracy: 0.7083\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4329 - accuracy: 0.8125 - val_loss: 0.4562 - val_accuracy: 0.7083\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4325 - accuracy: 0.8125 - val_loss: 0.4557 - val_accuracy: 0.7083\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4321 - accuracy: 0.8125 - val_loss: 0.4553 - val_accuracy: 0.7083\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4317 - accuracy: 0.8125 - val_loss: 0.4549 - val_accuracy: 0.7083\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4313 - accuracy: 0.8125 - val_loss: 0.4544 - val_accuracy: 0.7083\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4309 - accuracy: 0.8125 - val_loss: 0.4540 - val_accuracy: 0.7083\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4306 - accuracy: 0.8125 - val_loss: 0.4535 - val_accuracy: 0.7083\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4302 - accuracy: 0.8125 - val_loss: 0.4531 - val_accuracy: 0.7083\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4298 - accuracy: 0.8125 - val_loss: 0.4526 - val_accuracy: 0.7083\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4294 - accuracy: 0.8125 - val_loss: 0.4522 - val_accuracy: 0.7083\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4290 - accuracy: 0.8125 - val_loss: 0.4517 - val_accuracy: 0.7083\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4287 - accuracy: 0.8125 - val_loss: 0.4512 - val_accuracy: 0.7083\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4283 - accuracy: 0.8125 - val_loss: 0.4507 - val_accuracy: 0.7083\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4279 - accuracy: 0.8125 - val_loss: 0.4503 - val_accuracy: 0.7083\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4275 - accuracy: 0.8125 - val_loss: 0.4498 - val_accuracy: 0.7500\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4271 - accuracy: 0.8125 - val_loss: 0.4493 - val_accuracy: 0.7500\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4268 - accuracy: 0.8125 - val_loss: 0.4488 - val_accuracy: 0.7500\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4264 - accuracy: 0.8125 - val_loss: 0.4483 - val_accuracy: 0.7500\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4260 - accuracy: 0.8125 - val_loss: 0.4478 - val_accuracy: 0.7500\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4256 - accuracy: 0.8125 - val_loss: 0.4474 - val_accuracy: 0.7500\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4252 - accuracy: 0.8125 - val_loss: 0.4469 - val_accuracy: 0.7500\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4249 - accuracy: 0.8125 - val_loss: 0.4464 - val_accuracy: 0.7500\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4245 - accuracy: 0.8125 - val_loss: 0.4459 - val_accuracy: 0.7500\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4241 - accuracy: 0.8125 - val_loss: 0.4455 - val_accuracy: 0.7500\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4237 - accuracy: 0.8125 - val_loss: 0.4450 - val_accuracy: 0.7500\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4234 - accuracy: 0.8229 - val_loss: 0.4445 - val_accuracy: 0.7500\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4230 - accuracy: 0.8229 - val_loss: 0.4441 - val_accuracy: 0.7500\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4226 - accuracy: 0.8229 - val_loss: 0.4436 - val_accuracy: 0.7500\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4222 - accuracy: 0.8229 - val_loss: 0.4432 - val_accuracy: 0.7500\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4219 - accuracy: 0.8229 - val_loss: 0.4427 - val_accuracy: 0.7500\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4215 - accuracy: 0.8229 - val_loss: 0.4423 - val_accuracy: 0.7500\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4211 - accuracy: 0.8229 - val_loss: 0.4418 - val_accuracy: 0.7500\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4207 - accuracy: 0.8229 - val_loss: 0.4414 - val_accuracy: 0.7500\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4204 - accuracy: 0.8229 - val_loss: 0.4410 - val_accuracy: 0.7500\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4200 - accuracy: 0.8229 - val_loss: 0.4405 - val_accuracy: 0.7500\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4196 - accuracy: 0.8229 - val_loss: 0.4401 - val_accuracy: 0.7500\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4192 - accuracy: 0.8229 - val_loss: 0.4396 - val_accuracy: 0.7500\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4189 - accuracy: 0.8229 - val_loss: 0.4392 - val_accuracy: 0.7500\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4185 - accuracy: 0.8229 - val_loss: 0.4387 - val_accuracy: 0.7500\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4181 - accuracy: 0.8229 - val_loss: 0.4383 - val_accuracy: 0.7500\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4177 - accuracy: 0.8229 - val_loss: 0.4378 - val_accuracy: 0.7500\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4174 - accuracy: 0.8229 - val_loss: 0.4373 - val_accuracy: 0.7500\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4170 - accuracy: 0.8229 - val_loss: 0.4369 - val_accuracy: 0.7500\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4166 - accuracy: 0.8333 - val_loss: 0.4364 - val_accuracy: 0.7500\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.4360 - val_accuracy: 0.7500\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4159 - accuracy: 0.8333 - val_loss: 0.4355 - val_accuracy: 0.7500\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4155 - accuracy: 0.8333 - val_loss: 0.4350 - val_accuracy: 0.7500\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4151 - accuracy: 0.8438 - val_loss: 0.4346 - val_accuracy: 0.7500\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4147 - accuracy: 0.8438 - val_loss: 0.4341 - val_accuracy: 0.7500\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4144 - accuracy: 0.8438 - val_loss: 0.4336 - val_accuracy: 0.7917\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4140 - accuracy: 0.8438 - val_loss: 0.4331 - val_accuracy: 0.7917\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4136 - accuracy: 0.8438 - val_loss: 0.4327 - val_accuracy: 0.7917\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4132 - accuracy: 0.8438 - val_loss: 0.4322 - val_accuracy: 0.7917\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4129 - accuracy: 0.8438 - val_loss: 0.4317 - val_accuracy: 0.7917\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4125 - accuracy: 0.8438 - val_loss: 0.4312 - val_accuracy: 0.7917\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4121 - accuracy: 0.8438 - val_loss: 0.4307 - val_accuracy: 0.7917\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4117 - accuracy: 0.8542 - val_loss: 0.4302 - val_accuracy: 0.7917\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4113 - accuracy: 0.8542 - val_loss: 0.4297 - val_accuracy: 0.7917\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4110 - accuracy: 0.8542 - val_loss: 0.4292 - val_accuracy: 0.7917\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4106 - accuracy: 0.8542 - val_loss: 0.4287 - val_accuracy: 0.7917\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4102 - accuracy: 0.8542 - val_loss: 0.4282 - val_accuracy: 0.7917\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4098 - accuracy: 0.8542 - val_loss: 0.4277 - val_accuracy: 0.7917\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4095 - accuracy: 0.8542 - val_loss: 0.4272 - val_accuracy: 0.7917\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4091 - accuracy: 0.8542 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4087 - accuracy: 0.8542 - val_loss: 0.4262 - val_accuracy: 0.8333\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4083 - accuracy: 0.8542 - val_loss: 0.4257 - val_accuracy: 0.8333\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4079 - accuracy: 0.8542 - val_loss: 0.4252 - val_accuracy: 0.8333\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4076 - accuracy: 0.8542 - val_loss: 0.4246 - val_accuracy: 0.8333\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4072 - accuracy: 0.8542 - val_loss: 0.4241 - val_accuracy: 0.8333\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4068 - accuracy: 0.8542 - val_loss: 0.4236 - val_accuracy: 0.8333\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4064 - accuracy: 0.8542 - val_loss: 0.4231 - val_accuracy: 0.8333\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4060 - accuracy: 0.8542 - val_loss: 0.4226 - val_accuracy: 0.8333\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4057 - accuracy: 0.8542 - val_loss: 0.4221 - val_accuracy: 0.8333\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4053 - accuracy: 0.8542 - val_loss: 0.4216 - val_accuracy: 0.8333\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4049 - accuracy: 0.8542 - val_loss: 0.4211 - val_accuracy: 0.8333\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4045 - accuracy: 0.8542 - val_loss: 0.4206 - val_accuracy: 0.8333\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4041 - accuracy: 0.8542 - val_loss: 0.4201 - val_accuracy: 0.8333\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4038 - accuracy: 0.8542 - val_loss: 0.4196 - val_accuracy: 0.8333\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4034 - accuracy: 0.8542 - val_loss: 0.4191 - val_accuracy: 0.8333\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4030 - accuracy: 0.8542 - val_loss: 0.4186 - val_accuracy: 0.8333\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4026 - accuracy: 0.8542 - val_loss: 0.4181 - val_accuracy: 0.8333\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4022 - accuracy: 0.8542 - val_loss: 0.4176 - val_accuracy: 0.8333\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4018 - accuracy: 0.8542 - val_loss: 0.4171 - val_accuracy: 0.8333\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4015 - accuracy: 0.8542 - val_loss: 0.4166 - val_accuracy: 0.8750\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4011 - accuracy: 0.8542 - val_loss: 0.4161 - val_accuracy: 0.8750\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4007 - accuracy: 0.8542 - val_loss: 0.4156 - val_accuracy: 0.8750\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4003 - accuracy: 0.8542 - val_loss: 0.4151 - val_accuracy: 0.8750\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3999 - accuracy: 0.8542 - val_loss: 0.4146 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the ANN\n",
    "#training = model.fit(X_train, y_train, batch_size = 10000, validation_split=0.2, epochs = 100, class_weight={0:1.0, 1:1000.0})\n",
    "training = model.fit(X_train_scaled, y_train, batch_size = 10000, validation_split=0.2, epochs = 600, verbose=1)\n",
    "\n",
    "# plot the cost function over epoch\n",
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.title('Loss Function vs Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# plot confusion matrix\n",
    "# cf = confusion_matrix(y_test, y_test_pred.round(0))\n",
    "# display = ConfusionMatrixDisplay(cf)\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in = y_test_pred\n",
    "\n",
    "y_out = []\n",
    "for sample in y_in:\n",
    "    y_out.append(sample.argmax())\n",
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8785111 , 0.10329975, 0.01818917],\n",
       "       [0.05961557, 0.47912934, 0.4612551 ],\n",
       "       [0.0058511 , 0.30205888, 0.69209003],\n",
       "       [0.00279874, 0.25178704, 0.7454142 ],\n",
       "       [0.06068058, 0.49065712, 0.4486623 ],\n",
       "       [0.00559312, 0.2941751 , 0.70023185],\n",
       "       [0.01180665, 0.37623554, 0.6119578 ],\n",
       "       [0.06717077, 0.49371192, 0.4391173 ],\n",
       "       [0.06666499, 0.48415756, 0.44917738],\n",
       "       [0.9075662 , 0.08057198, 0.01186187],\n",
       "       [0.06355133, 0.49185428, 0.44459438],\n",
       "       [0.8996063 , 0.08676105, 0.01363264],\n",
       "       [0.90849954, 0.07965197, 0.01184853],\n",
       "       [0.01382763, 0.37585747, 0.61031497],\n",
       "       [0.1449999 , 0.5261254 , 0.32887477],\n",
       "       [0.00273478, 0.24986088, 0.7474043 ],\n",
       "       [0.0101967 , 0.3544668 , 0.6353365 ],\n",
       "       [0.00625422, 0.3083464 , 0.68539935],\n",
       "       [0.02097415, 0.4169284 , 0.56209743],\n",
       "       [0.08629384, 0.502994  , 0.41071212],\n",
       "       [0.00304475, 0.26413512, 0.7328201 ],\n",
       "       [0.00099738, 0.2011953 , 0.79780734],\n",
       "       [0.04484631, 0.47425494, 0.4808988 ],\n",
       "       [0.9085198 , 0.07963558, 0.01184454],\n",
       "       [0.13289854, 0.5174845 , 0.34961691],\n",
       "       [0.90948945, 0.07969665, 0.01081384],\n",
       "       [0.8861034 , 0.09739832, 0.01649828],\n",
       "       [0.00923229, 0.3427309 , 0.6480369 ],\n",
       "       [0.89010686, 0.09457085, 0.0153224 ],\n",
       "       [0.1078293 , 0.52255344, 0.36961725]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2637a4237c9832f1722b2cd300ef9b76dbc03b8bb4d86f4166da260fe841abb3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
